

```
  '''
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(8*100*16, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Reshape((8, 100, 16)))

  model.add(keras.layers.Conv2DTranspose(8, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())

  model.add(keras.layers.Conv2DTranspose(4, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # try to increase the possibility of dropout in generator(G) to increase the performance of the G
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(8*100*16, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.3))

  model.add(keras.layers.Reshape((8, 100, 16)))

  model.add(keras.layers.Conv2DTranspose(8, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(4, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # the case of ntimes is 9
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(9*100*16, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.3))

  model.add(keras.layers.Reshape((9, 100, 16)))

  model.add(keras.layers.Conv2DTranspose(8, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(4, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Apple
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(9*100*16, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.2))

  model.add(keras.layers.Reshape((9, 100, 16)))

  model.add(keras.layers.Conv2DTranspose(8, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(4, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Banana
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(9*100*32, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.2))

  model.add(keras.layers.Reshape((9, 100, 32)))

  model.add(keras.layers.Conv2DTranspose(16, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(8, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Cranberry
  # Cranberry will change the strides of Conv2D layer
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*50*64, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.2))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 50, 64)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(32, (3, 2), strides=(3, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(16, (1, 2), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Cranberry alpha
  # Cranberry alpha will change the neruons in the first layer from 3*50*64 to 3*50*32
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*160*32, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.2))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 160, 32)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(16, (3, 2), strides=(3, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(8, (2, 2), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (2, 2), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''
  
  '''
  # Durian
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*160*20, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.2))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 160, 20)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(10, (3, 3), strides=(3, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))
  
  model.add(keras.layers.Conv2DTranspose(5, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Durian alpha
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*100*20, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.2))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 100, 20)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(10, (3, 3), strides=(3, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))
  
  model.add(keras.layers.Conv2DTranspose(55, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Eleplant
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*100*20, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.2))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 100, 20)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(10, (3, 3), strides=(3, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))
  
  model.add(keras.layers.Conv2DTranspose(5, (1, 1), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''
  
  '''
  # Frambuesa
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*100*10, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 100, 10)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(5, (3, 3), strides=(3, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Galia Melon
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*50*32, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 50, 32)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(16, (3, 3), strides=(3, 3), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(8, (3, 3), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Helen melon
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*75*32, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 75, 32)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(16, (3, 3), strides=(3, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(8, (3, 3), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (1, 1), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))
  '''

  '''
  # Ierlia melon
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*25*32, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 25, 32)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(16, (3, 3), strides=(3, 3), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(8, (3, 3), strides=(1, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh'))  
  '''
  
  ''' trash
  # Jeck melon
  # batch size = 128
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*25*64, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 25, 64)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(32, (3, 3), strides=(3, 3), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(16, (3, 3), strides=(1, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh')) 
  '''

  '''
  # kyle
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(3*25*32, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((3, 25, 32)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(16, (3, 3), strides=(1, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(8, (3, 3), strides=(3, 3), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU())
  model.add(keras.layers.Dropout(0.1))

  model.add(keras.layers.Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh')) 
  '''

  '''
  # linda melon
  model = tf.keras.Sequential()
  model.add(keras.layers.Dense(9*25*64, use_bias=False, input_shape=(latent_space,)))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU(0.2))
  model.add(keras.layers.Dropout(0.3))

  # reshape(A,B,C)
  model.add(keras.layers.Reshape((9,25,64)))

  # strides = (a,b): a * A = ntimes, b * B = latent space
  # kernel size = (c,d): 
  model.add(keras.layers.Conv2DTranspose(64, (2, 2), strides=(1, 2), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU(0.2))
  model.add(keras.layers.Dropout(0.3))

  model.add(keras.layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', use_bias=False))
  model.add(keras.layers.BatchNormalization())
  model.add(keras.layers.LeakyReLU(0.2))
  model.add(keras.layers.Dropout(0.3))

  model.add(keras.layers.Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', output_padding=[0,0], use_bias=False, activation='tanh')) 
  '''


```

